{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# все библиотеки\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from itertools import product\n",
    "%matplotlib inline\n",
    "import seaborn\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# считывание данных\n",
    "\n",
    "df_pion = pd.read_csv('data/v1_pion_train.csv')\n",
    "df_kaon = pd.read_csv('data/v1_kaon_train.csv')\n",
    "df_electron = pd.read_csv('data/v1_electron_train.csv')\n",
    "df_ghost = pd.read_csv('data/v1_ghost_train.csv')\n",
    "df_muon = pd.read_csv('data/v1_muon_train.csv')\n",
    "df_proton = pd.read_csv('data/v1_proton_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_cols = ['TrackP', 'TrackEta', 'NumLongTracks']\n",
    "y_cols = ['RichDLLbt', 'RichDLLk', 'RichDLLmu', 'RichDLLp', 'RichDLLe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_masks(count, features, bins):\n",
    "    masks = {}\n",
    "    for col in features.columns:\n",
    "        mask = np.zeros((len(features[col]), count), dtype=np.bool)\n",
    "        mask[:, 0], mask[:, -1] = features[col] <= bins[col][0], features[col] > bins[col][-1]\n",
    "        for i in range(count - 2):\n",
    "            mask[:,i+1] = (bins[col][i] < features[col]) & (features[col] <= bins[col][i+1])\n",
    "        masks[col] = mask\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def train(self, X, Y, n_bins=5):\n",
    "        self.means = dict.fromkeys(Y.columns, np.zeros((n_bins, n_bins, n_bins)))\n",
    "        self.stds = dict.fromkeys(Y.columns, np.zeros((n_bins, n_bins, n_bins)))\n",
    "        self.bins = {}\n",
    "        for col in X.columns:\n",
    "            self.bins[col] = np.percentile(X[col], 100*np.linspace(1./n_bins, (n_bins-1)/n_bins,n_bins-1))\n",
    "        self.masks = create_masks(n_bins, X, self.bins)\n",
    "        \n",
    "        for i in range(n_bins):\n",
    "            for j in range(n_bins):\n",
    "                for k in range(n_bins):\n",
    "                    cols = X.columns\n",
    "                    f_masks = np.logical_and(self.masks[cols[0]][:,i], \n",
    "                                             self.masks[cols[1]][:,j],\n",
    "                                             self.masks[cols[2]][:,k]) \n",
    "                    for col in Y.columns:\n",
    "                        self.means[col][i,j,k] = np.mean(Y[col][f_masks])\n",
    "                        self.stds[col][i,j,k] = np.std (Y[col][f_masks])\n",
    "        \n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = pd.DataFrame()\n",
    "        count = np.zeros((self.means['RichDLLk'].shape), dtype=int)\n",
    "        n_bins = count.shape[0]\n",
    "        pred_masks = create_masks(n_bins, X, self.bins)\n",
    "\n",
    "        for i in range(n_bins):\n",
    "            for j in range(n_bins):\n",
    "                for k in range(n_bins):\n",
    "                    count[i,j,k] = np.count_nonzero(np.logical_and(masks[cols[0]][:,i],\n",
    "                                                                   masks[cols[1]][:,j],\n",
    "                                                                   masks[cols[2]][:,k]))\n",
    "        for col in self.means.keys():\n",
    "            samples = np.array([])\n",
    "            for i in range(n_bins):\n",
    "                for j in range(n_bins):\n",
    "                    for k in range(n_bins):\n",
    "                        cols = X.columns\n",
    "                        samples = np.append(samples,\n",
    "                                         np.random.normal(\n",
    "                                            loc=self.means[col][i,j,k],\n",
    "                                            scale=self.stds[col][i,j,k],\n",
    "                                            size=count[i,j,k]\n",
    "                                         )\n",
    "                                        )\n",
    "            pred[col] = samples\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://github.com/SiLiKhon/RICH_GAN_misc/blob/master/coopetition/scoring_program/score.py\n",
    "\n",
    "def score_func(sample1, sample2):\n",
    "    score = 0\n",
    "    cols = sample1.columns\n",
    "    w_normal = np.random.normal(size=(100, len(cols)))\n",
    "    reference = sample1.copy()[cols].values\n",
    "    prediction = sample2.copy()[cols].values\n",
    "    for k in range(100):\n",
    "        score = max(score,\n",
    "                    ks_2samp(\n",
    "                        np.sum(w_normal[k] * reference, axis=1), \n",
    "                        np.sum(w_normal[k] * prediction, axis=1)\n",
    "                    )[0]\n",
    "                   )\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'masks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d617e0f3dde3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmodel_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-9fb73cb2310d>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                     count[i,j,k] = np.count_nonzero(np.logical_and(masks[cols[0]][:,i],\n\u001b[0m\u001b[1;32m     32\u001b[0m                                                                    \u001b[0mmasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                                                                    masks[cols[2]][:,k]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'masks' is not defined"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "model_scores = []\n",
    "best_scores  = []\n",
    "\n",
    "for train_index, test_index in kf.split(df_pion[x_cols]):\n",
    "    X_train = df_pion[x_cols].iloc[train_index]\n",
    "    Y_train = df_pion[y_cols].iloc[train_index]\n",
    "    X_test  = df_pion[x_cols].iloc[test_index ]\n",
    "    Y_test  = df_pion[y_cols].iloc[test_index ]\n",
    "  \n",
    "    model = Model()\n",
    "    model.train(X_train.copy(), Y_train.copy())\n",
    "    Y_pred = model.predict(X_test.copy())\n",
    "  \n",
    "    model_scores.append(score_func(Y_test, Y_pred))\n",
    "    best_scores.append(score_func(Y_test, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in Y_pred.columns:\n",
    "    plt.subplots(figsize=(20, 10))\n",
    "    plt.grid()\n",
    "    _, bins, _ = plt.hist(Y_test[col], bins=100 , label='test'      )\n",
    "    _, _   , _ = plt.hist(Y_pred[col], bins=bins, label='prediction', alpha=0.7)\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlim(left=-200)\n",
    "    plt.xlabel(col)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.09064270e+01,  2.68801740e+04,  5.37406729e+04,  8.06011719e+04])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(df_kaon.TrackPt, 3, retbins=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 733.72082519,  766.3895874 ,  454.28909302, ...,  998.46643066,\n",
       "        191.11610413, 1095.25842285])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df_kaon.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(trX, trY, col, target bins=5, n_splits=5)\n",
    "    lr = LinearRegression(normalize=True)\n",
    "    _, bound_bins = pd.cut(trX, bins, retbins=True)\n",
    "    curX, curY = trX[col], trY[target]\n",
    "    cur_train = pd.concat([curX, curY])\n",
    "    model_scores = []\n",
    "    best_scores  = []\n",
    "    for i in range(1, bound_bins.shape[0]):\n",
    "        kf = KFold(n_splits=n_splits)\n",
    "        train_bin = cur_train.loc[(cur_train[col] > bins[i-1]) & (cur_train[col] <= bins[i])]\n",
    "        for train_index, test_index in kf.split(cur_train):\n",
    "            b_trX, b_trY = train_bin[col].iloc[train_index], train_bin[target].iloc[train_index]\n",
    "            b_teX, b_teY = train_bin[col].iloc[test_index], train_bin[target].iloc[test_index]\n",
    "            lr.fit(b_trX, b_trY)\n",
    "            model_scores.append(score_func(Y_test, Y_pred))\n",
    "            best_scores .append(score_func(Y_test, Y_train))\n",
    "            \n",
    "\n",
    "def test(teX, teY):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trX, teX, trY, teY = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    for col in x_cols:\n",
    "        for target in y_cols:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.RichDLL_count = 3\n",
    "        self.features = 5\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        self.discriminator = self.build_discriminator(loss='binary_crossentropy',\n",
    "                                                      optimizer=optimizer,\n",
    "                                                      metrics=['accuracy'])\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        \n",
    "        def build_generator(self):\n",
    "            model = Sequential()\n",
    "            model.add(Dense(128, input_dim=self.latent_dim))\n",
    "            model.add(LeakyReLU(alpha=0.1))\n",
    "            model.add(BatchNormalization(momentum=0.8))\n",
    "            model.add(Dense(3, activation='tanh'))\n",
    "            \n",
    "            model.summary()\n",
    "\n",
    "            noise = Input(shape=(self.features,))\n",
    "            RichDLLs = model(noise)\n",
    "            return Model(noise, RichDLLs)\n",
    "        \n",
    "        def build_discriminator(self):\n",
    "            model = Sequential()\n",
    "            model.add(Dense(128))\n",
    "            model.add(LeakyReLU(alpha=0.1))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            \n",
    "            model.summary()\n",
    "\n",
    "            RichDLLs = Input(shape=self.RichDLL_count)\n",
    "            validity = model(RichDLLs)\n",
    "            return Model(RichDLLs, validity)\n",
    "        \n",
    "        def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "            #Load the dataset\n",
    "            for epoch in range(epochs):\n",
    "                gen_RichDLLs = self.generator.predict(noise)\n",
    "if __name__ == '__main__':\n",
    "    gan = GAN()\n",
    "    gan.train(epochs=30000, batch_size=32, sample_interval=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cramer GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
